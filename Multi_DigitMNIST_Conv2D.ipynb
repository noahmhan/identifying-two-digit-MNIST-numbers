{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDv2//rFMBQpobmO7vW5vc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahmhan/identifying-two-digit-MNIST-numbers/blob/main/Multi_DigitMNIST_Conv2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIOrGeskepvR"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import numpy as np\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sxvn-wHSgT__",
        "outputId": "959f50e6-5367-447c-89a2-2ba92f0a01a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random2DigitMNIST():\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "  nX_train = np.array([])\n",
        "  nY_train = np.array([])\n",
        "  for i in range(6000):\n",
        "    r1 = random.randint(0, len(x_train)-1)\n",
        "    d1 = x_train[r1]\n",
        "    y1 = y_train[r1]\n",
        "\n",
        "    r2 = random.randint(0, len(x_train)-1)\n",
        "    d2 = x_train[r2]\n",
        "    y2 = y_train[r2]\n",
        "\n",
        "    nXvalue = np.hstack((d1, d2))\n",
        "    nXvalue = nXvalue[:, ::2]\n",
        "    nYvalue = 10*y1+y2\n",
        "\n",
        "    nX_train = np.append(nX_train, nXvalue)\n",
        "    nY_train = np.append(nY_train, nYvalue)\n",
        "\n",
        "\n",
        "  nX_test = np.array([])\n",
        "  nY_test = np.array([])\n",
        "  for i in range(1000):\n",
        "    r1 = random.randint(0, len(x_test)-1)\n",
        "    d1 = x_test[r1]\n",
        "    y1 = y_test[r1]\n",
        "\n",
        "    r2 = random.randint(0, len(x_test)-1)\n",
        "    d2 = x_test[r2]\n",
        "    y2 = y_test[r2]\n",
        "\n",
        "    nXvalue = np.hstack((d1, d2))\n",
        "    nXvalue = nXvalue[:, ::2]\n",
        "    nYvalue = 10*y1+y2\n",
        "\n",
        "    nX_test = np.append(nX_test, nXvalue)\n",
        "    nY_test = np.append(nY_test, nYvalue)\n",
        "\n",
        "\n",
        "\n",
        "  return nX_train, nY_train, nX_test, nY_test\n",
        "\n",
        "nX_train, nY_train, nX_test, nY_test = random2DigitMNIST()"
      ],
      "metadata": {
        "id": "rV0Im50TgkR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nX_train = nX_train.reshape(6000, 28, 28, 1).astype(\"float32\") / 255\n",
        "nX_test = nX_test.reshape(1000, 28, 28, 1).astype(\"float32\") / 255\n",
        "\n",
        "nY_train = nY_train.astype(\"float32\")\n",
        "nY_test = nY_test.astype(\"float32\")\n",
        "\n",
        "x_shift = copy.deepcopy(nX_test)\n",
        "y_shift = copy.deepcopy(nY_test)\n",
        "\n",
        "for i in range(1000):\n",
        "  rShift = random.randint(-5, 5)\n",
        "  rAxis = random.randint(0, 1)\n",
        "  x_shift[i] = np.roll(x_shift[i], rShift, axis = rAxis)\n",
        "\n"
      ],
      "metadata": {
        "id": "kdPGfZ9MD_ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape = (28, 28, 1))\n",
        "layer = Conv2D(16,kernel_size=3,activation='relu')(inputs)\n",
        "layer = BatchNormalization()(layer)\n",
        "layer = Conv2D(16,kernel_size=5,strides=2,padding='same',activation='relu')(layer)\n",
        "layer = BatchNormalization()(layer)\n",
        "layer = Dropout(0.4)(layer)\n",
        "\n",
        "layer = Flatten()(layer)\n",
        "layer = Dense(128, activation=\"relu\")(layer)\n",
        "layer = BatchNormalization()(layer)\n",
        "layer = Dropout(0.4)(layer)\n",
        "outputs = Dense(100)(layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k-fJNAHEvCp",
        "outputId": "be86298d-c8d9-4f72-c68f-34c785ef3b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mnist_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 16)        160       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 26, 26, 16)       64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 16)        6416      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 13, 13, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 13, 13, 16)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2704)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               346240    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               12900     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 366,356\n",
            "Trainable params: 366,036\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "-Qx8Wej7Evsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    nX_train,\n",
        "    nY_train,\n",
        "    batch_size=64,\n",
        "    epochs=30,\n",
        "    validation_split=0.2,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gfuaZ2iEzXX",
        "outputId": "e1f85153-f713-4f6c-8b34-8483f683a141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "75/75 [==============================] - 6s 71ms/step - loss: 4.0985 - accuracy: 0.1138 - val_loss: 4.2626 - val_accuracy: 0.0908\n",
            "Epoch 2/30\n",
            "75/75 [==============================] - 7s 96ms/step - loss: 2.3799 - accuracy: 0.3927 - val_loss: 3.9657 - val_accuracy: 0.1317\n",
            "Epoch 3/30\n",
            "75/75 [==============================] - 8s 107ms/step - loss: 1.6289 - accuracy: 0.5771 - val_loss: 3.5222 - val_accuracy: 0.2550\n",
            "Epoch 4/30\n",
            "75/75 [==============================] - 5s 70ms/step - loss: 1.1646 - accuracy: 0.7210 - val_loss: 2.9384 - val_accuracy: 0.4858\n",
            "Epoch 5/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.8556 - accuracy: 0.7996 - val_loss: 2.2183 - val_accuracy: 0.6658\n",
            "Epoch 6/30\n",
            "75/75 [==============================] - 5s 73ms/step - loss: 0.6653 - accuracy: 0.8479 - val_loss: 1.5665 - val_accuracy: 0.7783\n",
            "Epoch 7/30\n",
            "75/75 [==============================] - 6s 73ms/step - loss: 0.5270 - accuracy: 0.8777 - val_loss: 0.9164 - val_accuracy: 0.8467\n",
            "Epoch 8/30\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.4136 - accuracy: 0.9127 - val_loss: 0.6916 - val_accuracy: 0.8808\n",
            "Epoch 9/30\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.3319 - accuracy: 0.9337 - val_loss: 0.5315 - val_accuracy: 0.8900\n",
            "Epoch 10/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.2938 - accuracy: 0.9404 - val_loss: 0.4387 - val_accuracy: 0.8983\n",
            "Epoch 11/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.2434 - accuracy: 0.9479 - val_loss: 0.3828 - val_accuracy: 0.9017\n",
            "Epoch 12/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.2044 - accuracy: 0.9613 - val_loss: 0.3580 - val_accuracy: 0.9033\n",
            "Epoch 13/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.1828 - accuracy: 0.9679 - val_loss: 0.3359 - val_accuracy: 0.9092\n",
            "Epoch 14/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.1562 - accuracy: 0.9710 - val_loss: 0.3256 - val_accuracy: 0.9083\n",
            "Epoch 15/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.1496 - accuracy: 0.9710 - val_loss: 0.3119 - val_accuracy: 0.9075\n",
            "Epoch 16/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.1292 - accuracy: 0.9794 - val_loss: 0.2818 - val_accuracy: 0.9192\n",
            "Epoch 17/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.1138 - accuracy: 0.9808 - val_loss: 0.2917 - val_accuracy: 0.9200\n",
            "Epoch 18/30\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.1058 - accuracy: 0.9808 - val_loss: 0.2770 - val_accuracy: 0.9183\n",
            "Epoch 19/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.1031 - accuracy: 0.9812 - val_loss: 0.2773 - val_accuracy: 0.9142\n",
            "Epoch 20/30\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.0884 - accuracy: 0.9829 - val_loss: 0.2672 - val_accuracy: 0.9208\n",
            "Epoch 21/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.0907 - accuracy: 0.9802 - val_loss: 0.2852 - val_accuracy: 0.9167\n",
            "Epoch 22/30\n",
            "75/75 [==============================] - 5s 73ms/step - loss: 0.0765 - accuracy: 0.9871 - val_loss: 0.2540 - val_accuracy: 0.9283\n",
            "Epoch 23/30\n",
            "75/75 [==============================] - 5s 69ms/step - loss: 0.0733 - accuracy: 0.9854 - val_loss: 0.2551 - val_accuracy: 0.9225\n",
            "Epoch 24/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.0676 - accuracy: 0.9892 - val_loss: 0.2695 - val_accuracy: 0.9192\n",
            "Epoch 25/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.0658 - accuracy: 0.9877 - val_loss: 0.2740 - val_accuracy: 0.9158\n",
            "Epoch 26/30\n",
            "75/75 [==============================] - 5s 67ms/step - loss: 0.0579 - accuracy: 0.9879 - val_loss: 0.2537 - val_accuracy: 0.9242\n",
            "Epoch 27/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.0609 - accuracy: 0.9852 - val_loss: 0.2793 - val_accuracy: 0.9058\n",
            "Epoch 28/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.0587 - accuracy: 0.9885 - val_loss: 0.2720 - val_accuracy: 0.9158\n",
            "Epoch 29/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.0503 - accuracy: 0.9915 - val_loss: 0.2627 - val_accuracy: 0.9217\n",
            "Epoch 30/30\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.0532 - accuracy: 0.9902 - val_loss: 0.2398 - val_accuracy: 0.9283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(nX_test, nY_test,)\n",
        "print(\"test loss, test accuracy:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF6fNlPzFVuQ",
        "outputId": "e431b051-ca51-4c91-985b-bedb7a859109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2410 - accuracy: 0.9270\n",
            "test loss, test accuracy: [0.24104686081409454, 0.9269999861717224]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(x_shift, y_shift,)\n",
        "print(\"test loss, test accuracy:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1mKuSVHPh9l",
        "outputId": "4ed1d908-5c42-458c-fe2f-651edd2a10b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 12ms/step - loss: 4.1082 - accuracy: 0.3860\n",
            "test loss, test accuracy: [4.108234882354736, 0.38600000739097595]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 2\n",
        "plt.imshow(nX_train[i].reshape(28, 28),cmap='Greys')\n",
        "pred = model.predict(nX_train[i].reshape(-1, 28, 28, 1))\n",
        "print(\"Prediction: \", pred.argmax())\n",
        "label = int(nY_train[i])\n",
        "print(\"Label: \", label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "v41AgrBY9wph",
        "outputId": "d3666a93-01df-48c2-dbeb-8ea03e13332b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:  97\n",
            "Label:  97\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}